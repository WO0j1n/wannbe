# ================================================================
# TF-OFFICIAL-EXACT C-BSN (PyTorch FINAL, LDCT SAFE + CHECKPOINT)
# ================================================================

import os, glob, random, argparse # os: ê²½ë¡œ ë° ë””ë ‰í† ë¦¬ ê´€ë¦¬, glob: íŒŒì¼ ê²½ë¡œ ì¡°íšŒ, argparse: CLIì—ì„œ argument ë„˜ê²¨ ë°›ê¸°
import numpy as np
from tqdm import tqdm # progress bar

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.utils.checkpoint import checkpoint

from PIL import Image, ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True # PIL ì´ë¯¸ì§€ ë¡œë“œ ì‹œ ì†ìƒëœ ì´ë¯¸ì§€ë„ ë¡œë“œí•˜ë„ë¡ ì„¤ì •

# ================================================================
# Device
# ================================================================
device = torch.device(
    "cuda" if torch.cuda.is_available()
    else "mps" if torch.backends.mps.is_available()
    else "cpu"
)
print("ğŸ”¥ Device:", device)

# ================================================================
# Checkpoint config (LDCT SAFE ì „ìš©)
# ================================================================
CKPT_DIR_NAME  = "ckpt_cbsn_ldct_safe"
CKPT_FILE_NAME = "C_BSN_LDCT_ckpt.pt"

# ================================================================
# Utils
# ================================================================
def torch_normalize_ct(x): # ë…¼ë¬¸ì—ì„œëŠ” ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•Šì§€ë§Œ, ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•œ ì •ê·œí™”ëŠ” ìˆ˜í–‰í•˜ë„ë¡ í•¨.
    return x / 255.0

def torch_augmentation(x, seed): # ë°ì´í„° ì¦ê°• í•¨ìˆ˜, ì‹œë“œë¥¼ ì´ìš©í•´ íšŒì „ ë° ë’¤ì§‘ê¸° ìˆ˜í–‰  
    # Datasetì—ì„œ unsqeeze(0)ë¥¼ í–ˆìœ¼ë¯€ë¡œ ì°¨ì›ì€ (1, C, H, W)
    torch.manual_seed(seed)
    k = seed % 4
    x = torch.rot90(x, k=k, dims=[2, 3])  # H, W ì¶• ê¸°ì¤€ìœ¼ë¡œ kë²ˆ íšŒì „
    if (seed // 4) % 2:
        x = torch.flip(x, dims=[3]) # W ì¶• ê¸°ì¤€ìœ¼ë¡œ ìƒí•˜ë°˜ì „
    return x

def stop_grad(x): # l_invì—ì„œ anchorë¡œ ì‚¬ìš©ë˜ëŠ” í…ì„œì— ëŒ€í•´ gradientê°€ ê°€ì§€ ì•Šë„ë¡ í•˜ëŠ” í•¨ìˆ˜
    return x.detach()

def pad_to_multiple(x, s): # CT ì´ë¯¸ì§€ì— ëŒ€í•´ strideì˜ ë°°ìˆ˜ë¡œ íŒ¨ë”©ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    B, C, H, W = x.shape
    pad_h = (s - H % s) % s
    pad_w = (s - W % s) % s
    if pad_h == 0 and pad_w == 0:
        return x
    return F.pad(x, (0, pad_w, 0, pad_h), mode="reflect")

# ================================================================
# TF VarianceScaling (fan_in, scale=2), convolution weight ì´ˆê¸°í™”
# ================================================================
def tf_variance_scaling_(w):
    kH, kW = w.shape[2], w.shape[3] # w shape: (out_channels, in_channels, kH, kW), convì—ì„œëŠ” (in_channels, out_channels, kH, kW)ì¸ë° ê·¸ ì•ˆì— ìˆëŠ” weightëŠ” (out_channels, in_channels, kH, kW)
    # fan_in ê³„ì‚° -> ë…¼ë¬¸ êµ¬í˜„ì—ì„œ ì‚¬ìš©í•œ ë°©ì‹ìœ¼ë¡œ, fan_inì€ ì…ë ¥ ì±„ë„ ìˆ˜ * ì»¤ë„ ë†’ì´ * ì»¤ë„ ë„ˆë¹„
    fan_in = w.shape[1] * kH * kW
    std = (2.0 / fan_in) ** 0.5 # # He initialization ê¸°ë²•
    with torch.no_grad():
        w.normal_(0.0, std)

# ================================================================
# Random Subsampler (NO gradient)
# ================================================================
class RandomSubsampler(nn.Module):
    def __init__(self, stride=2):
        super().__init__()
        self.s = stride

    def forward(self, x):
        with torch.no_grad(): # Downsamplingì˜ ê²½ìš°, gradientê°€ í•„ìš” ì—†ìœ¼ë¯€ë¡œ no_grad ì‚¬ìš©
            B, C, H, W = x.shape
            s = self.s
            x = x.view(B, C, H//s, s, W//s, s)
            ih = torch.randint(0, s, (B,1,H//s,1,W//s,1), device=x.device)
            iw = torch.randint(0, s, (B,1,H//s,1,W//s,1), device=x.device)
            out = x.gather(3, ih.expand(-1,C,-1,-1,-1,s)) # [B, C, H//s, s, W//s, s] -> gather(3, ...) -> [B, C, H//s, 1, W//s, s]
            out = out.gather(5, iw.expand(-1,C,-1,-1,-1,-1)) # [B, C, H//s, 1, W//s, s] -> gather(5, ...) -> [B, C, H//s, 1, W//s, 1]
            return out.squeeze(5).squeeze(3) # ìµœì¢… shape: [B, C, H//s, W//s]

# ================================================================
# Space2Batch / Batch2Space
# ================================================================
def space2batch(x, s):
    B, C, H, W = x.shape
    assert H % s == 0 and W % s == 0, "patch must be divisible by stride_b"
    x = x.view(B, C, H//s, s, W//s, s) # [B, C, H, W] -> [B, C, H//s, s, W//s, s]
    x = x.permute(0,3,5,1,2,4) # [B, C, H//s, s, W//s, s] -> [B, s, s, C, H//s, W//s]
    return x.reshape(B*s*s, C, H//s, W//s) # [B, s, s, C, H//s, W//s] -> [B*s*s, C, H//s, W//s]

def batch2space(x, s, B):
    _, C, H, W = x.shape
    x = x.view(B, s, s, C, H, W) # [B*s*s, C, H//s, W//s] -> [B, s, s, C, H//s, W//s]
    x = x.permute(0,3,4,1,5,2) # [B, s, s, C, H//s, W//s] -> [B, C, H//s, s, W//s, s]
    return x.reshape(B, C, H*s, W*s) # [B, C, H//s, s, W//s, s] -> [B, C, H, W]

# ================================================================
# Masked Convolution
# ================================================================
class MaskedConv2d(nn.Module):
    def __init__(self, cin, cout, k, dilation):
        super().__init__()
        self.k = k # ì»¤ë„ í¬ê¸°
        self.pad = (k // 2) * dilation # íŒ¨ë”© í¬ê¸° ê³„ì‚°
        self.dilation = dilation # dilation ì„¤ì •

        self.weight = nn.Parameter(torch.empty(cout, cin, k, k)) # convolution weight, shape: (out_channels, in_channels, kH, kW)
        self.center_weight = nn.Parameter(torch.empty(cout, cin, 1, 1)) # ë§ˆìŠ¤í¬ ì—¬ë¶€ì— ë”°ë¥¸ ì¤‘ì•™ ê°€ì¤‘ì¹˜, shape: (out_channels, in_channels, 1, 1)
        self.bias = nn.Parameter(torch.zeros(cout))

        tf_variance_scaling_(self.weight) # convolution weight kaiming ì´ˆê¸°í™” ìˆ˜í–‰
        tf_variance_scaling_(self.center_weight)

    def forward(self, x, is_masked):
        w = self.weight.clone()
        if is_masked:
            w[:, :, self.k//2, self.k//2] = 0.0 # is_maksedê°€ Trueì¸ ê²½ìš°, ì¤‘ì•™ weightë¥¼ 0ìœ¼ë¡œ ì„¤ì •
        else:
            w[:, :, self.k//2, self.k//2] = \
                self.center_weight.squeeze(-1).squeeze(-1) # is_maskedê°€ Falseì¸ ê²½ìš°, ë³„ë„ì˜ ì¤‘ì•™ weightë¡œ ëŒ€ì²´, [out, in 1, 1]]
        return F.relu(
            # nn.Conv2dì˜ ê²½ìš°, layerë¥¼ ì˜ë¯¸í•˜ëŠ”ë° ì´ë•Œ, ê·¸ ì•ˆì— íŒŒë¼ë¯¸í„°ëŠ” ê³µìœ í•˜ê¸° ì–´ë ¤ì›€, F.conv2dëŠ” í•¨ìˆ˜ë¡œ ì§ì ‘ weight, biasë¥¼ ë„£ì–´ì£¼ë©´ ë˜ë©° ê°€ì¤‘ì¹˜ë¥¼ ê³µìœ í•  ìˆ˜ ìˆìŒ
            F.conv2d(x, w, self.bias, padding=self.pad, dilation=self.dilation)
        )

# ================================================================
# 1x1 Conv / DCM
# ================================================================
class Conv1x1(nn.Module):
    def __init__(self, cin, cout, act=True):
        super().__init__()
        self.conv = nn.Conv2d(cin, cout, 1)
        self.act = nn.ReLU(inplace=False) if act else nn.Identity()
        tf_variance_scaling_(self.conv.weight) # convolution weight ì´ˆê¸°í™”
        nn.init.zeros_(self.conv.bias) # biasëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™”

    def forward(self, x):
        return self.act(self.conv(x))

class DCM(nn.Module): # # Dilated Convolution Moduleë¡œ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ DCM êµ¬í˜„, AP-BSNì—ì„œ ìƒìš”í•œ moduleê³¼ ë™ì¼í•¨
    def __init__(self, c, dilation):
        super().__init__()
        self.conv1 = nn.Conv2d(c, c, 3, padding=dilation, dilation=dilation)
        self.conv2 = nn.Conv2d(c, c, 1)
        tf_variance_scaling_(self.conv1.weight) # convolution weight ì´ˆê¸°í™”
        tf_variance_scaling_(self.conv2.weight) # convolution weight ì´ˆê¸°í™”
        nn.init.zeros_(self.conv1.bias) # biasëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™”
        nn.init.zeros_(self.conv2.bias) # biasëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™”

    def forward(self, x):
        f = F.relu(self.conv1(x))
        f = F.relu(self.conv2(f))
        return x + f # residual connection

# ================================================================
# Branch / CBSN
# ================================================================
class BranchTF(nn.Module): # AP-BSNì—ì„œ ë‚´ë¶€ filtersëŠ” ëª¨ë‘ 128ë¡œ ê³ ì •
    def __init__(self, filters, k, dilation, num_module):
        super().__init__()
        self.masked = MaskedConv2d(filters, filters, k, 1) # # maskedconvì—ì„œëŠ” dilation=1ë¡œ ì„¤ì •í•´ì„œ ìˆ˜í–‰
        self.c1 = Conv1x1(filters, filters)
        self.c2 = Conv1x1(filters, filters)
        self.dcms = nn.ModuleList(
            [DCM(filters, dilation) for _ in range(num_module)]
        )
        self.c3 = Conv1x1(filters, filters)

    def forward(self, x, is_masked):
        x = self.masked(x, is_masked)
        x = self.c1(x)
        x = self.c2(x)
        for dcm in self.dcms:
            x = checkpoint(dcm, x) # forwardì—ì„œ gradientë¥¼ ê³„ì‚°í•  ë•Œ, ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ê¸° ìœ„í•´ checkpointing ì‚¬ìš©
        return self.c3(x)

class CBSN(nn.Module):
    def __init__(self):
        super().__init__()
        self.head = Conv1x1(1, 128) # LDCTì˜ ê²½ìš°, in_channel = 1, masked conv ì´ì „ì— 1x1 conv ìˆ˜í–‰
        self.b1 = BranchTF(128, 3, 2, 9) # ì²« ë²ˆì§¸ ë¸Œëœì¹˜ë¡œ 3x3 ì»¤ë„, dilation=2, 9ê°œì˜ DCM ëª¨ë“ˆ ì‚¬ìš©
        self.b2 = BranchTF(128, 5, 3, 9) # ë‘ ë²ˆì§¸ ë¸Œëœì¹˜ë¡œ 5x5 ì»¤ë„, dilation=3, 9ê°œì˜ DCM ëª¨ë“ˆ ì‚¬ìš©
        self.f1 = Conv1x1(256, 128) # ë‘ ë¸Œëœì¹˜ì˜ ì¶œë ¥ì„ í•©ì¹œ í›„ 1x1 conv ìˆ˜í–‰
        self.f2 = Conv1x1(128, 64) # 1x1 conv ìˆ˜í–‰
        self.f3 = Conv1x1(64, 64) # 1x1 conv ìˆ˜í–‰
        self.out = Conv1x1(64, 1, act=False) # ìµœì¢… ì¶œë ¥ ì±„ë„ì€ 1, í™œì„±í™” í•¨ìˆ˜ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

    def forward(self, x, is_masked):
        f = self.head(x)
        x = torch.cat( # ë‘ ë¸Œëœì¹˜ì˜ ì¶œë ¥ì„ ì±„ë„ ì°¨ì›ì—ì„œ ì—°ê²°
            [self.b1(f, is_masked), self.b2(f, is_masked)],
            dim=1
        )
        return self.out(self.f3(self.f2(self.f1(x))))

# ================================================================
# Dataset
# ================================================================
class LDCTDataset(Dataset):
    def __init__(self, root, patch):
        self.files = sorted(
            glob.glob(os.path.join(root, '**', '*.png'), recursive=True) +
            glob.glob(os.path.join(root, '**', '*.PNG'), recursive=True)
        )
        assert len(self.files) > 0, "âŒ No LDCT images found"
        self.patch = patch

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        '''
        __getitem__ì˜ process:
        1) ì´ë¯¸ì§€ ë¡œë“œ (L ëª¨ë“œ, í‘ë°±)
        2) í…ì„œ ë³€í™˜ ë° ì°¨ì› ì¶”ê°€ (C, H, W) -> (1, C, H, W)
        3) íŒ¨ì¹˜ í¬ê¸°ë³´ë‹¤ ì‘ì„ ê²½ìš°, ë°˜ì‚¬ íŒ¨ë”© ìˆ˜í–‰
        4) ëœë¤í•˜ê²Œ íŒ¨ì¹˜ í¬ê¸°ë§Œí¼ ìë¥´ê¸°
        5) ë°ì´í„° ì¦ê°• ìˆ˜í–‰ (íšŒì „ ë° ë’¤ì§‘ê¸°)
        6) ì •ê·œí™” ìˆ˜í–‰
        7) ì°¨ì› ì¶•ì†Œ ë° ë°˜í™˜ (C, H, W)
        '''
        img = Image.open(self.files[idx]).convert("L")
        img = torch.from_numpy(np.array(img, np.float32))[None]
        H, W = img.shape[-2:]
        if H < self.patch or W < self.patch:
            img = F.pad(
                img,
                (0, max(0, self.patch-W), 0, max(0, self.patch-H)),
                mode="reflect"
            )
        t = random.randint(0, img.shape[-2]-self.patch)
        l = random.randint(0, img.shape[-1]-self.patch)
        img = img[:, t:t+self.patch, l:l+self.patch][None]
        return torch_normalize_ct(
            torch_augmentation(img, idx)
        ).squeeze(0)

# ================================================================
# Training
# ================================================================
def train(args):
    ckpt_dir  = os.path.join(os.getcwd(), CKPT_DIR_NAME)
    ckpt_path = os.path.join(ckpt_dir, CKPT_FILE_NAME)
    os.makedirs(ckpt_dir, exist_ok=True)

    model = CBSN().to(device)
    opt   = torch.optim.Adam(model.parameters(), lr=args.lr, eps=1e-8)
    rs    = RandomSubsampler(args.stride_i).to(device)

    start_step = 0
    if args.resume and os.path.exists(ckpt_path):
        print(f"ğŸ” Resume from {ckpt_path}")
        ckpt = torch.load(ckpt_path, map_location=device)
        model.load_state_dict(ckpt["model"])
        opt.load_state_dict(ckpt["optimizer"])
        start_step = ckpt["step"] + 1
        print(f"â¡ï¸ Resumed at step {start_step}")

    loader = DataLoader(
        LDCTDataset(args.train_data_dir, args.patch),
        batch_size=1,
        shuffle=True,
        num_workers=4,
        pin_memory=True
    )
    it = iter(loader)

    for step in tqdm(range(start_step, args.max_iter),
                     desc="ğŸ”¥ C-BSN LDCT SAFE"):
        try:
            img = next(it).to(device)
        except StopIteration:
            it = iter(loader)
            img = next(it).to(device)

        img_b = pad_to_multiple(img, args.stride_b)
        pd = space2batch(img_b, args.stride_b)
        out_blind = batch2space(
            model(pd, True),
            args.stride_b,
            img_b.size(0)
        )
        l_blind = F.l1_loss(out_blind, img_b)

        if step < 200_000:
            loss = l_blind
        else:
            img_i = pad_to_multiple(img, args.stride_i)
            l_self = F.l1_loss(model(img_i, False), img_i)
            with torch.no_grad():
                target = stop_grad(model(rs(img_i), True))
            pred = rs(model(img_i, False))
            loss = l_blind + l_self + args.lambda_inv * F.l1_loss(pred, target)

        opt.zero_grad()
        loss.backward()
        opt.step()

        if step % 10000 == 0 and step > 0:
            torch.save(
                {
                    "step": step,
                    "model": model.state_dict(),
                    "optimizer": opt.state_dict(),
                    "args": vars(args)
                },
                ckpt_path
            )
            print(f"ğŸ’¾ Saved checkpoint @ step {step}")

# ================================================================
# Main
# ================================================================
if __name__ == "__main__":
    p = argparse.ArgumentParser()
    p.add_argument("--train_data_dir", type=str, default= "/home/work/LDCT/Sharp Kernel (D45) quater")
    p.add_argument("--patch", type=int, default=512)
    p.add_argument("--stride_b", type=int, default=5)
    p.add_argument("--stride_i", type=int, default=2)
    p.add_argument("--lambda_inv", type=float, default=2.0)
    p.add_argument("--lr", type=float, default=1e-4)
    p.add_argument("--max_iter", type=int, default=500000)
    p.add_argument("--resume", action="store_true")
    args = p.parse_args()

    train(args)
