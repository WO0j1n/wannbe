# ================================================================
# TF-OFFICIAL-EXACT C-BSN (PyTorch FINAL + CHECKPOINT)
# - Bit-faithful loss schedule
# - Exact gradient semantics
# - Conditional blind-spot
# - RS / S2B / B2S identical to TF graph
# - Checkpoint save / resume / eval ready
# ================================================================

import os, glob, random, argparse # os: ê²½ë¡œ, í´ë” ìƒì„±, glob: íŒŒì¼ ê²€ìƒ‰, argparse: CLI Argument ë°›ê¸°
import numpy as np
from tqdm import tqdm # í•™ìŠµ progess bar

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.utils.tensorboard import SummaryWriter

from PIL import Image, ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True # ì†ìƒëœ ì´ë¯¸ì§€ ë¡œë“œ í—ˆìš©, ì˜¤ë¥˜ ë°©ì§€

# ================================================================
# Device
# ================================================================
device = torch.device(
    "cuda" if torch.cuda.is_available()
    else "mps" if torch.backends.mps.is_available()
    else "cpu"
)
print("ğŸ”¥ Device:", device)

CKPT_NAME = "C_BSN_SIDD_ckpy.pt"  # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì´ë¦„


# unsqueeze(0) -> (C, H, W) -> (1, C, H, W), 0ì´ ì•ì—ë‹¤ ì¶”ê°€, 1ì´ ë’¤ì—ë‹¤ ì¶”ê°€
# squeeze(0) -> (1, C, H, W) -> (C, H, W), íŠ¹ì •ì°¨ì›ì„ ì—†ì• ê³  ì‹¶ìœ¼ë¡œ í•¨ìˆ˜ ì•ˆì— indexë¥¼ ë„£ì–´ì£¼ë©´ ë¨, ì•„ë‹ˆë©´ ì°¨ì›ì´ 1ì¸ ëª¨ë“  ì°¨ì›ì„ ì—†ì•°
# view() -> tensorì˜ shape ë³€ê²½, reshapeê³¼ ìœ ì‚¬í•˜ì§€ë§Œ, viewëŠ” ë©”ëª¨ë¦¬ ìƒì—ì„œ ì—°ì†ì ì¸ ê²½ìš°ì—ë§Œ ì‚¬ìš© ê°€ëŠ¥
# permute() -> ì°¨ì› ìˆœì„œ ë³€ê²½
# reshape() -> tensorì˜ shape ë³€ê²½, viewì™€ ìœ ì‚¬í•˜ì§€ë§Œ, ë©”ëª¨ë¦¬ ìƒì—ì„œ ì—°ì†ì ì´ì§€ ì•Šì•„ë„ ì‚¬ìš© ê°€ëŠ¥ + ë³µì‚¬ ê°€ëŠ¥í•˜ê¸°ì— ìƒˆë¡œìš´ tensor ìƒì„±
# ë³´í†µ view() -> reshape() ìˆœìœ¼ë¡œ ì‚¬ìš© ê¶Œì¥
# gather() -> íŠ¹ì • ì°¨ì›ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°’ì„ ì„ íƒí•˜ëŠ” í•¨ìˆ˜, ì¸ë±ìŠ¤ í…ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ì›í•˜ëŠ” ìœ„ì¹˜ì˜ ê°’ì„ ì¶”ì¶œ


# ================================================================
# Utils
# ================================================================
def torch_normalize(x): # ì¼ë‹¨, ë…¼ë¬¸ì—ì„œ ì •ê·œí™”ë¥¼ í•˜ì§€ ì•ŠëŠ”ë‹¤ê³  í–ˆì–´ë„ ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•œ ì •ê·œí™”ëŠ” í•„ìš”, 0~255 -> 0~1
    return x / 255.0

def torch_augmentation(x, seed): # Datasetì—ì„œ unsqeeze(0)ë¥¼ í–ˆìœ¼ë¯€ë¡œ ì°¨ì›ì€ (1, C, H, W)
    torch.manual_seed(seed)
    k = seed % 4
    x = torch.rot90(x, k=k, dims=[2, 3]) # H, W ì¶• ê¸°ì¤€ìœ¼ë¡œ íšŒì „
    if (seed // 4) % 2: 
        x = torch.flip(x, dims=[3]) # ìˆ˜í‰ ë’¤ì§‘ê¸°
    return x

def stop_grad(x): # ë³¸ ë…¼ë¬¸ì—ì„œ, l_inv ê³„ì‚° ì‹œ ahchorì—ëŠ” gradientê°€ ê°€ì§€ ì•Šë„ë¡ detach() ì‚¬ìš©
    return x.detach() # .detach()ëŠ” requires_grad=Trueì¸ í…ì„œì—ì„œ gradient ê³„ì‚°ì„ ë©ˆì¶”ê²Œ í•¨, shpaeì— ë³€í™” ì—†ìŒ

# ================================================================
# TF VarianceScaling (fan_in, scale=2), convolution weight ì´ˆê¸°í™”
# ================================================================
def tf_variance_scaling_(w): # TensorFlowì˜ VarianceScaling ì´ˆê¸°í™” (fan_in, scale=2)
    kH, kW = w.shape[2], w.shape[3] # w shape: (out_channels, in_channels, kH, kW), convì—ì„œëŠ” (in_channels, out_channels, kH, kW)ì¸ë° ê·¸ ì•ˆì— ìˆëŠ” weightëŠ” (out_channels, in_channels, kH, kW)
    # fan_in ê³„ì‚° -> ë…¼ë¬¸ êµ¬í˜„ì—ì„œ ì‚¬ìš©í•œ ë°©ì‹ìœ¼ë¡œ, fan_inì€ ì…ë ¥ ì±„ë„ ìˆ˜ * ì»¤ë„ ë†’ì´ * ì»¤ë„ ë„ˆë¹„
    fan_in = w.shape[1] * kH * kW
    std = (2.0 / fan_in) ** 0.5 # He initialization ê¸°ë²•
    with torch.no_grad():
        w.normal_(0.0, std)

# ================================================================
# Random Subsampler (NO gradient)
# ================================================================
class RandomSubsampler(nn.Module):
    def __init__(self, stride=2):
        super().__init__()
        self.s = stride

    def forward(self, x):
        with torch.no_grad(): # RSì˜ ê²½ìš°, ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ì§€ ì•ŠìŒ
            B, C, H, W = x.shape
            s = self.s
            x = x.view(B, C, H//s, s, W//s, s)

            ih = torch.randint(0, s, (B,1,H//s,1,W//s,1), device=x.device) # ê° ë¸”ë¡ë§ˆë‹¤ ë½‘ì„ (h_offset, w_offset)ì„ ëœë¤í•˜ê²Œ ì„ íƒ
            iw = torch.randint(0, s, (B,1,H//s,1,W//s,1), device=x.device) # ê° ë¸”ë¡ë§ˆë‹¤ ë½‘ì„ (h_offset, w_offset)ì„ ëœë¤í•˜ê²Œ ì„ íƒ

            out = x.gather(3, ih.expand(-1,C,-1,-1,-1,s)) #[B, C, H//s, s, W//s, s] -> gather(3, ...) -> [B, C, H//s, 1, W//s, s]
            out = out.gather(5, iw.expand(-1,C,-1,-1,-1,-1)) #[B, C, H//s, 1, W//s, s] -> gather(5, ...) -> [B, C, H//s, 1, W//s, 1]
            return out.squeeze(5).squeeze(3) # squeeze -> [B, C, H//s, W//s]

# ================================================================
# Space2Batch / Batch2Space (gradient ON)
# ================================================================
def space2batch(x, s):
    B, C, H, W = x.shape
    assert H % s == 0 and W % s == 0, "Patch must be divisible by stride_b" # space2batchëŠ” stride_bë¡œ ë‚˜ëˆ„ì–´ ë–¨ì–´ì ¸ì•¼ í•¨
    x = x.view(B, C, H//s, s, W//s, s) # [B, C, H//s, s, W//s, s]
    x = x.permute(0,3,5,1,2,4) # [B, s, s, C, H//s, W//s]
    return x.reshape(B*s*s, C, H//s, W//s) # [B*s*s, C, H//s, W//s], space2batchëŠ” ë°°ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ë¸”ë¡ì„ ë‚˜ëˆ„ì–´ ë°°ì¹˜ í¬ê¸°ë¥¼ ëŠ˜ë¦¼

def batch2space(x, s, B): # batch2spaceëŠ” space2batchì˜ ì—­ì—°ì‚°, BëŠ” ì›ë˜ ë°°ì¹˜ í¬ê¸°
    _, C, H, W = x.shape
    x = x.view(B, s, s, C, H, W) # [B, s, s, C, H, W]
    x = x.permute(0,3,4,1,5,2) # [B, C, H, s, W, s]
    return x.reshape(B, C, H*s, W*s) # [B, C, H*s, W*s], batch2spaceëŠ” ë°°ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ë¸”ë¡ì„ í•©ì³ ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì„

# ================================================================
# Masked Convolution (TF-exact)
# ================================================================
class MaskedConv2d(nn.Module):
    def __init__(self, cin, cout, k, dilation):
        super().__init__()
        self.k = k # kernel size
        self.pad = (k // 2) * dilation # padding_size ê³„ì‚°, TF 'SAME' paddingê³¼ ë™ì¼ íŠ¹íˆ, dilationì„ í™œìš©í•˜ëŠ” ê²½ìš°, k // 2 * dilationìœ¼ë¡œ ìˆ˜í–‰
        self.dilation = dilation # dilation

        self.weight = nn.Parameter(torch.empty(cout, cin, k, k)) # convolution weight, shape: (out_channels, in_channels, kH, kW)
        self.center_weight = nn.Parameter(torch.empty(cout, cin, 1, 1)) # maskedì˜ ê²½ìš°, ì¤‘ì•™ì„ 0ìœ¼ë¡œ ë§Œë“¤ê¸° ë•Œë¬¸ì— Unmasked ì‹œì— ì‚¬ìš©í•  ì¤‘ì•™ weight
        self.bias = nn.Parameter(torch.zeros(cout)) # bias

        tf_variance_scaling_(self.weight) # convolution weight kaiming ì´ˆê¸°í™” ìˆ˜í–‰
        tf_variance_scaling_(self.center_weight) # ë§ˆìŠ¤í¬ ì—¬ë¶€ì— ë”°ë¥¸ ì¤‘ì•™ weightë„ ì´ˆê¸°í™”

    def forward(self, x, is_masked):
        w = self.weight.clone()
        if is_masked:
            w[:, :, self.k//2, self.k//2] = 0.0  # is_maksedê°€ Trueì¸ ê²½ìš°, ì¤‘ì•™ weightë¥¼ 0ìœ¼ë¡œ ì„¤ì •
        else:
            w[:, :, self.k//2, self.k//2] = \
                self.center_weight.squeeze(-1).squeeze(-1)  # is_maskedê°€ Falseì¸ ê²½ìš°, ë³„ë„ì˜ ì¤‘ì•™ weightë¡œ ëŒ€ì²´, [out, in 1, 1]]

        out = F.conv2d( # nn.Conv2dì˜ ê²½ìš°, layerë¥¼ ì˜ë¯¸í•˜ëŠ”ë° ì´ë•Œ, ê·¸ ì•ˆì— íŒŒë¼ë¯¸í„°ëŠ” ê³µìœ í•˜ê¸° ì–´ë ¤ì›€, F.conv2dëŠ” í•¨ìˆ˜ë¡œ ì§ì ‘ weight, biasë¥¼ ë„£ì–´ì£¼ë©´ ë˜ë©° ê°€ì¤‘ì¹˜ë¥¼ ê³µìœ í•  ìˆ˜ ìˆìŒ
            x, w, self.bias,
            padding=self.pad,
            dilation=self.dilation
        )
        return F.relu(out)

# ================================================================
# 1x1 Conv
# ================================================================
class Conv1x1(nn.Module):
    def __init__(self, cin, cout, act=True):
        super().__init__()
        self.conv = nn.Conv2d(cin, cout, 1)
        self.act = nn.ReLU(inplace=False) if act else nn.Identity()
        tf_variance_scaling_(self.conv.weight) # 1x1 convolution weight ì´ˆê¸°í™”
        nn.init.zeros_(self.conv.bias) # 1x1 convolution bias ì´ˆê¸°í™”

    def forward(self, x):
        return self.act(self.conv(x))

# ================================================================
# Dilated Convolution Module (DCM)
# ================================================================
class DCM(nn.Module): # Dilated Convolution Moduleë¡œ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ DCM êµ¬í˜„, AP-BSNì—ì„œ ìƒìš”í•œ moduleê³¼ ë™ì¼í•¨
    def __init__(self, c, dilation):
        super().__init__()
        self.conv1 = nn.Conv2d(c, c, 3, padding=dilation, dilation=dilation)
        self.conv2 = nn.Conv2d(c, c, 1)
        self.relu = nn.ReLU(inplace=False)

        tf_variance_scaling_(self.conv1.weight) # convoluition weight ì´ˆê¸°í™”
        tf_variance_scaling_(self.conv2.weight) # convolution weight ì´ˆê¸°í™”
        nn.init.zeros_(self.conv1.bias) # convolution bias ì´ˆê¸°í™”
        nn.init.zeros_(self.conv2.bias) # convolution bias ì´ˆê¸°í™”

    def forward(self, x):
        f = self.relu(self.conv1(x))
        f = self.relu(self.conv2(f))
        return x + f # skip connction

# ================================================================
# Branch (TF style)
# ================================================================
from torch.utils.checkpoint import checkpoint

class BranchTF(nn.Module): # AP-BSNì—ì„œ ë‚´ë¶€ filtersëŠ” ëª¨ë‘ 128ë¡œ ê³ ì •
    def __init__(self, filters, k, dilation, num_module):
        super().__init__()
        self.masked = MaskedConv2d(filters, filters, k, 1) # maskedconvì—ì„œëŠ” dilation=1ë¡œ ì„¤ì •í•´ì„œ ìˆ˜í–‰
        self.c1 = Conv1x1(filters, filters)
        self.c2 = Conv1x1(filters, filters)
        self.dcms = nn.ModuleList( # DCM ëª¨ë“ˆì„ MoudleListë¡œ ë°˜ë³µë¬¸ìœ¼ë¡œ ìƒì„±
            [DCM(filters, dilation) for _ in range(num_module)]
        )
        self.c3 = Conv1x1(filters, filters)

    def forward(self, x, is_masked):
        x = self.masked(x, is_masked)
        x = self.c1(x)
        x = self.c2(x)
        for dcm in self.dcms:
            x = checkpoint(dcm, x) # forwardì—ì„œ gradientë¥¼ ê³„ì‚°í•  ë•Œ, ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ê¸° ìœ„í•´ checkpointing ì‚¬ìš©
        return self.c3(x)

# ================================================================
# CBSN Network
# ================================================================
class CBSN(nn.Module):
    def __init__(self, in_channels=3, filters=128, num_module=9): # in_channels=3 (RGB), filters=128 (ë…¼ë¬¸ì—ì„œ ê³ ì •), num_module=9 (ë…¼ë¬¸ì—ì„œ ê³ ì •)
        super().__init__()
        self.head = Conv1x1(in_channels, filters) # maske conv ì „ì— 1x1 convë¡œ ì±„ë„ ìˆ˜ ë§ì¶¤
        self.b1 = BranchTF(filters, 3, 2, num_module)# ì²« ë²ˆì§¸ ë¸Œëœì¹˜: ì»¤ë„ í¬ê¸° 3, dilation 2, num_module ê°œìˆ˜
        self.b2 = BranchTF(filters, 5, 3, num_module)# ë‘ ë²ˆì§¸ ë¸Œëœì¹˜: ì»¤ë„ í¬ê¸° 5, dilation 3, num_module ê°œìˆ˜
        self.f1 = Conv1x1(filters*2, filters) # ë‘ ë¸Œëœì¹˜ ì¶œë ¥ ì±„ë„ì„ í•©ì³ì„œ 1x1 conv ìˆ˜í–‰
        self.f2 = Conv1x1(filters, 64) # 1x1 convë¡œ ì±„ë„ ìˆ˜ 64ë¡œ ê°ì†Œ
        self.f3 = Conv1x1(64, 64) # 1x1 convë¡œ ì±„ë„ ìˆ˜ 64ë¡œ ìœ ì§€
        self.out = Conv1x1(64, in_channels, act=False) # ìµœì¢… ì¶œë ¥ 1x1 conv, act=Falseë¡œ í™œì„±í™” í•¨ìˆ˜ ì—†ìŒ

    def forward(self, x, is_masked):
        f = self.head(x)
        b1 = self.b1(f, is_masked)
        b2 = self.b2(f, is_masked)
        x = torch.cat([b1, b2], dim=1) # ë‘ ë¸Œëœì¹˜ ì¶œë ¥ concatenate ìˆ˜í–‰, dim=1ì€ ì±„ë„ ì¶• ê¸°ì¤€
        x = self.f1(x)
        x = self.f2(x)
        x = self.f3(x)
        return self.out(x)

# ================================================================
# Dataset (SIDD noisy only)
# ================================================================
class SIDDDataset(Dataset):
    def __init__(self, root, patch=240):
        self.files = sorted(
            glob.glob(os.path.join(root, '*', 'NOISY_SRGB_*.png')) +
            glob.glob(os.path.join(root, '*', 'NOISY_SRGB_*.PNG'))
        )
        assert len(self.files) > 0, "âŒ No SIDD images found"
        self.patch = patch

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        '''
        __getitem__ì˜ process:
        1. ì´ë¯¸ì§€ ë¡œë“œ ë° RGB ë³€í™˜ - PIL ì‚¬ìš©
        2. NumPy ë°°ì—´ë¡œ ë³€í™˜ ë° float32 íƒ€ì…ìœ¼ë¡œ ìºìŠ¤íŒ… & ì±„ë„ ìš°ì„  í˜•ì‹ìœ¼ë¡œ ì „ì¹˜ (C, H, W)
        3. ë¬´ì‘ìœ„ë¡œ íŒ¨ì¹˜ ì¶”ì¶œ (patch í¬ê¸°)
        4. Patchë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜ ë° ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        5. ë°ì´í„° ì¦ê°• (ë¬´ì‘ìœ„ íšŒì „ ë° ë’¤ì§‘ê¸°)
        6. ì •ê·œí™” (0~255 -> 0~1)
        7. ë°°ì¹˜ ì°¨ì› ì œê±° ë° ë°˜í™˜
        8. ìµœì¢… ë°˜í™˜ í˜•íƒœ: (C, patch, patch)
        '''
        img = Image.open(self.files[idx]).convert("RGB")
        img = np.array(img).astype(np.float32).transpose(2,0,1)
        _, H, W = img.shape
        t = random.randint(0, H-self.patch)
        l = random.randint(0, W-self.patch)
        patch = torch.from_numpy(
            img[:, t:t+self.patch, l:l+self.patch]
        ).unsqueeze(0)
        patch = torch_augmentation(patch, idx)
        return torch_normalize(patch).squeeze(0)

# ================================================================
# Training
# ================================================================
def train(args):
    os.makedirs(args.ckpt_dir, exist_ok=True)
    writer = SummaryWriter(args.ckpt_dir) # TensorBoard SummaryWriter ìƒì„±

    model = CBSN().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, eps=1e-8)

    start_step = 0
    ckpt_path = os.path.join(args.ckpt_dir, CKPT_NAME)

    # Checkpoint resume
    if args.resume and os.path.exists(ckpt_path):
        print(f"ğŸ” Resume from {ckpt_path}")
        ckpt = torch.load(ckpt_path, map_location=device)
        model.load_state_dict(ckpt["model"])
        optimizer.load_state_dict(ckpt["optimizer"])
        start_step = ckpt["step"] + 1
        print(f"â¡ï¸ Resumed at step {start_step}")

    rs = RandomSubsampler(args.stride_i).to(device) # RandomSubsampler ìƒì„± ë° ë””ë°”ì´ìŠ¤ í• ë‹¹

    # DataLoader
    loader = DataLoader(
        SIDDDataset(args.train_data_dir, args.patch),
        batch_size=1, shuffle=True, num_workers=4
    )

    it = iter(loader)
    warmup = 200_000

    for step in tqdm(range(start_step, args.max_iter),
                     desc="ğŸ”¥ TF-OFFICIAL-EXACT C-BSN"):
        try:
            img = next(it).to(device)
        except StopIteration:
            it = iter(loader)
            img = next(it).to(device)

        # Blind-spot loss
        pd = space2batch(img, args.stride_b)
        out_blind = batch2space(
            model(pd, is_masked=True),
            args.stride_b,
            img.size(0)
        )
        l_blind = F.l1_loss(out_blind, img)

        # Total loss
        # í•™ìŠµ ì´ˆê¸°ì—ëŠ” Warm-upì„ í™œìš©í•´ì„œ l_blindë§Œ ì‚¬ìš©
        if step < warmup:
            loss = l_blind
        else:
            out = model(img, is_masked=False)
            l_self = F.l1_loss(out, img)

            with torch.no_grad():
                ds_img = rs(img) # downsampled imageì˜ ê²½ìš°, gradientê°€ í•„ìš” ì—†ìœ¼ë¯€ë¡œ with torch.no_grad() ì‚¬ìš©

            target = stop_grad(model(ds_img, is_masked=True)) # anchorëŠ” gradientê°€ ê°€ì§€ ì•Šë„ë¡ stop_grad ì‚¬ìš©, l_inv ê³„ì‚° ì‹œì—ë§Œ ì‚¬ìš©
            pred = rs(model(img, is_masked=False))

            l_inv = F.l1_loss(pred, target)
            loss = l_blind + l_self + args.lambda_inv * l_inv

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        writer.add_scalar("Loss/blind", l_blind.item(), step)
        writer.add_scalar("Loss/total", loss.item(), step)
        if step >= warmup:
            writer.add_scalar("Loss/self", l_self.item(), step)
            writer.add_scalar("Loss/inv", l_inv.item(), step)

        if step % 10000 == 0 and step > 0:
            torch.save(
                {
                    "step": step,
                    "model": model.state_dict(),
                    "optimizer": optimizer.state_dict(),
                    "args": vars(args)
                },
                ckpt_path
            )
            print(f"ğŸ’¾ Saved checkpoint @ step {step}")

    writer.close()

# ================================================================
# Main
# ================================================================
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--train_data_dir", type=str, required=True)
    parser.add_argument("--ckpt_dir", type=str, default="./ckpt")
    parser.add_argument("--lr", type=float, default=1e-4)
    parser.add_argument("--max_iter", type=int, default=500000)
    parser.add_argument("--stride_b", type=int, default=5)
    parser.add_argument("--stride_i", type=int, default=2)
    parser.add_argument("--lambda_inv", type=float, default=2.0)
    parser.add_argument("--patch", type=int, default=240)
    parser.add_argument("--resume", action="store_true")
    args = parser.parse_args()

    train(args)



# python C_BSN_self.py \
#   --train_data_dir /home/work/AP-BSN/SIDD_Small_sRGB_Only/Data \
#   --ckpt_dir ./ckpt_cbsn_tf_exact \
#   --lr 1e-4 \
#   --max_iter 500000 \
#   --stride_b 5 \
#   --stride_i 2 \
#   --lambda_inv 2.0 \
#   --patch 240